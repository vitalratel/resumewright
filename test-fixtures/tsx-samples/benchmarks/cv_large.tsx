export default function LargeCV() {
  return (
    <div style="font-family: Arial, sans-serif">
      <header style="font-family: Georgia">
        <h1>Dr. María José García-Rodríguez PhD</h1>
        <p>maria.garcia+resume@example.com | +1-555-123-4567 | Boston, MA</p>
        <p>https://www.mariagarcia.com | linkedin.com/in/mariagarcia | github.com/mariagarcia</p>
      </header>
      
      <section>
        <h2>Professional Summary</h2>
        <p>
          Distinguished Senior Research Scientist and Technical Lead with 12+ years of experience 
          in artificial intelligence, machine learning, and distributed systems. Published author 
          with 25+ peer-reviewed papers and 500+ citations. Proven track record of leading 
          cross-functional teams, securing $5M+ in research funding, and delivering innovative 
          solutions that impact millions of users worldwide.
        </p>
      </section>
      
      <section>
        <h2>Professional Experience</h2>
        
        <article>
          <h3>Principal Research Scientist & Technical Lead</h3>
          <p><strong>AI Research Lab, Tech Giant Inc.</strong> | Cambridge, MA | 2020 - Present</p>
          <ul>
            <li>Lead research team of 15 scientists and engineers developing next-generation ML models</li>
            <li>Architected distributed training infrastructure processing 100PB+ datasets</li>
            <li>Published 8 papers at top-tier conferences (NeurIPS, ICML, ACL) with 200+ citations</li>
            <li>Reduced model training time by 60% through novel optimization techniques</li>
            <li>Mentored 10+ junior researchers and graduate student interns</li>
            <li>Secured $2.5M research grant for multi-year AI safety project</li>
            <li>Collaborated with product teams to deploy ML models serving 50M+ users</li>
            <li>Presented research findings at 15+ international conferences and workshops</li>
          </ul>
        </article>
        
        <article>
          <h3>Senior Research Scientist</h3>
          <p><strong>Machine Learning Institute</strong> | San Francisco, CA | 2017 - 2020</p>
          <ul>
            <li>Developed state-of-the-art natural language processing models for multiple languages</li>
            <li>Led cross-functional team building real-time ML inference system (10ms p99 latency)</li>
            <li>Published 6 papers with average 50 citations each in top conferences</li>
            <li>Built scalable data pipeline processing 10TB+ daily for model training</li>
            <li>Implemented A/B testing framework measuring ML model impact on key metrics</li>
            <li>Collaborated with ethics team on responsible AI guidelines and best practices</li>
            <li>Reduced infrastructure costs by 40% through efficient resource utilization</li>
            <li>Mentored 5 PhD students and reviewed 50+ conference paper submissions</li>
          </ul>
        </article>
        
        <article>
          <h3>Research Scientist</h3>
          <p><strong>University Research Center</strong> | Seattle, WA | 2014 - 2017</p>
          <ul>
            <li>Conducted fundamental research in deep learning and computer vision</li>
            <li>Developed novel neural architecture achieving state-of-the-art results on ImageNet</li>
            <li>Published 5 papers at CVPR, ICCV, and ECCV with 100+ total citations</li>
            <li>Secured $1.5M NSF grant for multi-institutional research collaboration</li>
            <li>Taught graduate courses on machine learning and neural networks</li>
            <li>Supervised 3 PhD students and 10+ master's thesis projects</li>
            <li>Built open-source framework adopted by 500+ researchers worldwide</li>
          </ul>
        </article>
        
        <article>
          <h3>Postdoctoral Research Fellow</h3>
          <p><strong>AI Lab, Top University</strong> | Cambridge, MA | 2012 - 2014</p>
          <ul>
            <li>Conducted postdoctoral research on reinforcement learning and robotics</li>
            <li>Published 6 papers in leading AI and robotics conferences</li>
            <li>Developed learning algorithms for autonomous navigation systems</li>
            <li>Collaborated with 5 research groups across 3 universities</li>
            <li>Presented research at 20+ academic seminars and industry workshops</li>
          </ul>
        </article>
      </section>
      
      <section>
        <h2>Education</h2>
        
        <article>
          <h3>Doctor of Philosophy (PhD) in Computer Science</h3>
          <p><strong>Massachusetts Institute of Technology</strong> | Cambridge, MA | 2012</p>
          <p>Dissertation: "Deep Hierarchical Models for Visual Recognition and Understanding"</p>
          <p>Advisor: Prof. Distinguished Researcher | GPA: 4.0/4.0</p>
          <p>Awards: Best Dissertation Award, NSF Graduate Research Fellowship</p>
        </article>
        
        <article>
          <h3>Master of Science (MS) in Artificial Intelligence</h3>
          <p><strong>Stanford University</strong> | Stanford, CA | 2008</p>
          <p>Thesis: "Machine Learning Approaches to Natural Language Understanding"</p>
          <p>GPA: 3.95/4.0 | Dean's List (all quarters)</p>
        </article>
        
        <article>
          <h3>Bachelor of Science (BS) in Computer Science & Mathematics</h3>
          <p><strong>University of California, Berkeley</strong> | Berkeley, CA | 2006</p>
          <p>Summa Cum Laude | GPA: 3.98/4.0 | Phi Beta Kappa</p>
          <p>Departmental Honors in both Computer Science and Mathematics</p>
        </article>
      </section>
      
      <section>
        <h2>Technical Skills</h2>
        
        <div style="font-family: Courier New">
          <p><strong>Programming Languages:</strong> Python, C++, Rust, Java, JavaScript, TypeScript, R, Julia, MATLAB</p>
          <p><strong>ML Frameworks:</strong> PyTorch, TensorFlow, JAX, scikit-learn, Hugging Face Transformers</p>
          <p><strong>Big Data:</strong> Spark, Hadoop, Flink, Kafka, Dask, Ray</p>
          <p><strong>Cloud & Infrastructure:</strong> AWS (SageMaker, EC2, S3), GCP (Vertex AI), Azure, Kubernetes, Docker</p>
          <p><strong>Databases:</strong> PostgreSQL, MySQL, MongoDB, Redis, Cassandra, ElasticSearch</p>
          <p><strong>Tools & Libraries:</strong> Git, Linux, NumPy, Pandas, CUDA, OpenMP, MPI</p>
          <p><strong>Specializations:</strong> Deep Learning, NLP, Computer Vision, Reinforcement Learning, MLOps</p>
        </div>
      </section>
      
      <section>
        <h2>Publications</h2>
        
        <div>
          <p><strong>Selected Recent Publications (25 total, 500+ citations):</strong></p>
          
          <p>[1] García-Rodríguez, M.J., et al. "Efficient Large-Scale Model Training with Distributed Optimization." 
          NeurIPS 2023. (85 citations)</p>
          
          <p>[2] García-Rodríguez, M.J., Smith, J. "Cross-Lingual Transfer Learning for Low-Resource Languages." 
          ACL 2023. (42 citations)</p>
          
          <p>[3] García-Rodríguez, M.J., et al. "Robust Neural Architectures for Adversarial Environments." 
          ICML 2022. (67 citations)</p>
          
          <p>[4] García-Rodríguez, M.J. "Theoretical Foundations of Deep Hierarchical Models." 
          JMLR 2021. (103 citations)</p>
          
          <p>[5] García-Rodríguez, M.J., et al. "Real-Time Inference Systems for Production ML." 
          MLSys 2021. (58 citations)</p>
          
          <p>[6] García-Rodríguez, M.J., Brown, A. "Attention Mechanisms for Multimodal Learning." 
          CVPR 2020. (92 citations)</p>
          
          <p><em>Full publication list available at: https://scholar.google.com/mariagarcia</em></p>
        </div>
      </section>
      
      <section>
        <h2>Awards & Honors</h2>
        
        <ul>
          <li>ACM Distinguished Scientist Award (2023)</li>
          <li>MIT Technology Review 35 Innovators Under 35 (2022)</li>
          <li>Best Paper Award, NeurIPS Conference (2022)</li>
          <li>IEEE Young Professional of the Year (2021)</li>
          <li>NSF CAREER Award (2019)</li>
          <li>Google Faculty Research Award (2018, 2020)</li>
          <li>Outstanding Dissertation Award, MIT (2012)</li>
          <li>NSF Graduate Research Fellowship (2007-2012)</li>
        </ul>
      </section>
      
      <section>
        <h2>Professional Service</h2>
        
        <div>
          <p><strong>Conference Organization:</strong></p>
          <ul>
            <li>Program Committee Chair: ICML 2024</li>
            <li>Area Chair: NeurIPS (2021-2023), ICLR (2020-2023)</li>
            <li>Senior Program Committee: AAAI (2019-2023)</li>
            <li>Workshop Organizer: 5 workshops at major ML conferences</li>
          </ul>
          
          <p><strong>Journal Editorial:</strong></p>
          <ul>
            <li>Associate Editor: Journal of Machine Learning Research (2021-Present)</li>
            <li>Guest Editor: IEEE Transactions on Pattern Analysis and Machine Intelligence (2022)</li>
            <li>Reviewer: 100+ papers for top-tier ML/AI conferences and journals</li>
          </ul>
          
          <p><strong>Community Leadership:</strong></p>
          <ul>
            <li>Co-founder: Women in Machine Learning (WiML) local chapter</li>
            <li>Board Member: AI for Social Good Initiative</li>
            <li>Mentor: 20+ underrepresented minorities in STEM programs</li>
          </ul>
        </div>
      </section>
      
      <section>
        <h2>Invited Talks & Teaching</h2>
        
        <ul>
          <li>Keynote Speaker: International Conference on Machine Learning (ICML) 2023</li>
          <li>Distinguished Lecturer: 15+ universities worldwide (2020-2023)</li>
          <li>Tutorial Instructor: "Advanced Deep Learning" at NeurIPS (2021, 2022)</li>
          <li>Guest Lecturer: Stanford University, MIT, UC Berkeley (2018-2023)</li>
          <li>Industry Talks: Google, Meta, Microsoft, Amazon, Apple (20+ presentations)</li>
        </ul>
      </section>
      
      <section>
        <h2>Patents & Intellectual Property</h2>
        
        <ul>
          <li>US Patent 11,234,567: "Efficient Neural Network Training with Gradient Compression" (2023)</li>
          <li>US Patent 10,987,654: "Real-Time ML Inference System Architecture" (2022)</li>
          <li>US Patent 10,765,432: "Cross-Lingual Transfer Learning Method" (2021)</li>
          <li>5 additional patents pending</li>
        </ul>
      </section>
      
      <section>
        <h2>Languages</h2>
        <p>Spanish (Native), English (Fluent), Portuguese (Proficient), French (Intermediate)</p>
      </section>
      
      <section>
        <h2>Professional Memberships</h2>
        <p>ACM (Senior Member), IEEE (Senior Member), AAAI (Fellow), Association for Computational Linguistics</p>
      </section>
      
      <footer style="font-family: Times New Roman">
        <p><em>References available upon request</em></p>
        <p>Last updated: October 2023</p>
      </footer>
    </div>
  );
}
